# Advanced Structlog Features for AgentFarm Simulation Framework

## Current Usage Assessment

### âœ… Already Using Well:
1. **Context Variables** (`structlog.contextvars`) - For simulation_id, step, etc.
2. **Custom Processors** - Timestamp, log level, censoring sensitive data
3. **Multiple Renderers** - JSON for production, colored console for dev
4. **Callsite Information** - File, function, line number tracking
5. **Context Managers** - `log_simulation()`, `log_step()`, `log_experiment()`
6. **BoundLogger** - Context binding with `.bind()`

### ðŸ”„ Features You Should Add:

---

## 1. Thread-Safe Context for Parallel Simulations

**Current Issue:** `contextvars` might not work correctly in thread pools for parallel experiments.

**Solution:** Use `structlog.threadlocal` for thread-safe context in parallel simulations.

```python
# farm/utils/logging_config.py

def configure_logging(
    environment: str = "development",
    use_threadlocal: bool = False,  # Add this parameter
    **kwargs
):
    processors: list[Processor] = [
        # Use threadlocal for parallel simulations
        structlog.threadlocal.merge_threadlocal if use_threadlocal 
        else structlog.contextvars.merge_contextvars,
        add_log_level,
        # ... rest of processors
    ]
    
    # Configure with threadlocal context class if needed
    structlog.configure(
        processors=processors,
        wrapper_class=structlog.make_filtering_bound_logger(numeric_level),
        context_class=dict if not use_threadlocal else structlog.threadlocal.wrap_dict(dict),
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )
```

**Usage:**
```python
# For parallel experiment runner
configure_logging(environment="production", use_threadlocal=True)

# Bind context in each thread
structlog.threadlocal.bind_threadlocal(
    experiment_id="exp_001",
    thread_id=thread_id
)
```

---

## 2. Better Exception Formatting with dict_tracebacks

**Current:** Using `format_exc_info` which gives string tracebacks.

**Better:** Use `dict_tracebacks` for structured exception data.

```python
# farm/utils/logging_config.py

def extract_exception_info(logger: Any, method_name: str, event_dict: EventDict) -> EventDict:
    """Extract exception information with structured traceback."""
    exc_info = event_dict.pop("exc_info", None)
    if exc_info:
        # Use dict_tracebacks for structured exception data
        event_dict["exception"] = structlog.processors.dict_tracebacks(
            logger, method_name, {"exc_info": exc_info}
        ).get("exception", [])
    return event_dict
```

**Benefits:**
- Machine-readable exception data
- Can filter/search by exception type
- Better for log analysis tools

**Example Output:**
```json
{
  "exception": [
    {
      "exc_type": "ValueError",
      "exc_value": "Invalid agent position",
      "syntax_error": null,
      "is_cause": false,
      "frames": [
        {
          "filename": "environment.py",
          "lineno": 1065,
          "name": "add_agent",
          "line": "raise ValueError('Invalid agent position')"
        }
      ]
    }
  ]
}
```

---

## 3. Performance Optimization with Filter-By-Level

**Current:** All processors run even when log level is disabled.

**Optimization:** Use `filter_by_level` to skip processing for disabled levels.

```python
# farm/utils/logging_config.py

def configure_logging(...):
    # Wrap processors that do expensive work
    processors: list[Processor] = [
        # Cheap processors (always run)
        structlog.contextvars.merge_contextvars,
        add_log_level,
        
        # Filter out disabled log levels early
        structlog.stdlib.filter_by_level,
        
        # Expensive processors (only run if level is enabled)
        add_logger_name,
        add_timestamp,
        structlog.processors.StackInfoRenderer(),
        extract_exception_info,
        censor_sensitive_data,
        PerformanceLogger(slow_threshold_ms=100.0),
        
        # Callsite info is expensive - only in dev/debug
        *(
            [structlog.processors.CallsiteParameterAdder(...)]
            if include_caller_info
            else []
        ),
    ]
```

**Impact:** Can improve logging performance by 20-50% for disabled log levels.

---

## 4. Better Timestamp Handling

**Current:** Custom `add_timestamp` function.

**Better:** Use built-in `TimeStamper` processor.

```python
# farm/utils/logging_config.py

processors: list[Processor] = [
    structlog.contextvars.merge_contextvars,
    add_log_level,
    add_logger_name,
    
    # Replace custom add_timestamp with:
    structlog.processors.TimeStamper(fmt="iso", utc=True, key="timestamp"),
    
    # ... rest of processors
]
```

**Benefits:**
- More efficient (written in C for some formats)
- Supports multiple timestamp formats
- Handles timezone properly

**Format Options:**
```python
# ISO format (recommended for production)
structlog.processors.TimeStamper(fmt="iso", utc=True)  # "2025-10-07T05:30:15.123456Z"

# Unix timestamp (fastest)
structlog.processors.TimeStamper(fmt="timestamp", utc=True)  # 1728279015.123456

# Custom format
structlog.processors.TimeStamper(fmt="%Y-%m-%d %H:%M:%S", utc=True)
```

---

## 5. Unicode and Encoding Safety

**Issue:** Simulation logs might have non-ASCII agent names, special characters, etc.

**Solution:** Add `UnicodeDecoder` and `UnicodeEncoder` processors.

```python
# farm/utils/logging_config.py

processors: list[Processor] = [
    structlog.contextvars.merge_contextvars,
    
    # Decode unicode in event dict values
    structlog.processors.UnicodeDecoder(),
    
    add_log_level,
    # ... rest of processors
    
    # Before final renderer
    structlog.processors.UnicodeEncoder(encoding="utf-8", errors="replace"),
    
    # Renderer (JSON or Console)
    structlog.processors.JSONRenderer(),
]
```

---

## 6. Event Renaming for Clarity

**Current:** Event is stored in "event" key.

**Option:** Rename to "message" or "event_name" for clarity.

```python
# farm/utils/logging_config.py

processors: list[Processor] = [
    structlog.contextvars.merge_contextvars,
    add_log_level,
    
    # Rename 'event' to 'message' or 'event_name'
    structlog.processors.EventRenamer(to="message"),
    # or
    structlog.processors.EventRenamer(to="event_name"),
    
    # ... rest of processors
]
```

**Before:**
```json
{"event": "agent_added", "agent_id": "abc123", ...}
```

**After:**
```json
{"message": "agent_added", "agent_id": "abc123", ...}
```

---

## 7. Log Level Number for Filtering

**Use Case:** Log aggregation tools that filter by numeric level.

```python
# farm/utils/logging_config.py

def add_log_level_number(logger: Any, method_name: str, event_dict: EventDict) -> EventDict:
    """Add numeric log level for filtering."""
    level_map = {
        "debug": 10,
        "info": 20,
        "warning": 30,
        "error": 40,
        "critical": 50,
    }
    level_name = event_dict.get("level", "info")
    event_dict["level_num"] = level_map.get(level_name, 20)
    return event_dict

# Add to processor chain
processors: list[Processor] = [
    # ...
    add_log_level,
    add_log_level_number,  # Add this
    # ...
]
```

**Output:**
```json
{"level": "warning", "level_num": 30, "message": "resources_low", ...}
```

---

## 8. Testing Support with structlog.testing

**Use Case:** Unit tests for logging behavior.

```python
# tests/test_logging.py

import structlog
from structlog.testing import LogCapture

def test_agent_logging():
    """Test that agent actions are logged correctly."""
    # Capture logs during test
    cap = LogCapture()
    
    # Temporarily replace logger factory
    structlog.configure(
        processors=[
            structlog.processors.add_log_level,
            cap,  # Captures all log calls
        ],
        logger_factory=structlog.PrintLoggerFactory(),
    )
    
    # Run code that logs
    logger = structlog.get_logger()
    logger.info("agent_action", agent_id="test_001", action="move")
    
    # Assert logs
    assert len(cap.entries) == 1
    assert cap.entries[0]["event"] == "agent_action"
    assert cap.entries[0]["agent_id"] == "test_001"
    assert cap.entries[0]["action"] == "move"
```

**Create Test Helper:**
```python
# farm/utils/logging_test_helpers.py

from contextlib import contextmanager
from structlog.testing import LogCapture
import structlog

@contextmanager
def capture_logs():
    """Context manager to capture logs during tests."""
    cap = LogCapture()
    old_processors = structlog.get_config()["processors"]
    
    try:
        structlog.configure(
            processors=[
                structlog.processors.add_log_level,
                cap,
            ],
            logger_factory=structlog.PrintLoggerFactory(),
        )
        yield cap
    finally:
        structlog.configure(processors=old_processors)

# Usage in tests
def test_simulation_logging():
    with capture_logs() as logs:
        run_simulation(...)
        
        # Assert expected logs
        assert any(log["event"] == "simulation_started" for log in logs.entries)
        assert any(log["event"] == "simulation_completed" for log in logs.entries)
```

---

## 9. Correlation IDs for Distributed Tracing

**Use Case:** Track related events across simulation runs, API calls, etc.

```python
# farm/utils/logging_correlation.py

import uuid
import structlog

def add_correlation_id():
    """Add correlation ID to track related operations."""
    correlation_id = str(uuid.uuid4())[:8]  # Short ID
    structlog.contextvars.bind_contextvars(correlation_id=correlation_id)
    return correlation_id

# Usage
def run_simulation(...):
    correlation_id = add_correlation_id()
    
    logger.info("simulation_started", correlation_id=correlation_id)
    # All subsequent logs will include correlation_id
    
    # Can pass correlation_id to sub-operations
    analyze_results(correlation_id=correlation_id)
```

---

## 10. Custom Context Class for Performance

**Use Case:** Faster context operations for high-throughput logging.

```python
# farm/utils/logging_config.py

from structlog._config import BoundLoggerLazyProxy

class FastContext(dict):
    """Optimized context dict for high-performance logging."""
    
    __slots__ = ()  # No __dict__, saves memory
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    
    def new_child(self, child):
        """Create child context efficiently."""
        new = self.copy()
        new.update(child)
        return new

# Use in configure_logging
structlog.configure(
    processors=processors,
    wrapper_class=structlog.make_filtering_bound_logger(numeric_level),
    context_class=FastContext,  # Use custom context class
    logger_factory=structlog.PrintLoggerFactory(),
    cache_logger_on_first_use=True,
)
```

---

## 11. Async Logging Support

**Use Case:** Non-blocking logging for performance-critical simulations.

```python
# farm/utils/logging_async.py

import asyncio
import structlog
from concurrent.futures import ThreadPoolExecutor

class AsyncLogger:
    """Async wrapper for structlog logger."""
    
    def __init__(self, logger, executor=None):
        self.logger = logger
        self.executor = executor or ThreadPoolExecutor(max_workers=1)
        self.loop = asyncio.get_event_loop()
    
    async def info(self, event, **kwargs):
        """Async info log."""
        await self.loop.run_in_executor(
            self.executor,
            lambda: self.logger.info(event, **kwargs)
        )
    
    async def error(self, event, **kwargs):
        """Async error log."""
        await self.loop.run_in_executor(
            self.executor,
            lambda: self.logger.error(event, **kwargs)
        )

# Usage
async def run_simulation_async(...):
    logger = AsyncLogger(structlog.get_logger())
    
    await logger.info("simulation_started", simulation_id=sim_id)
    # ... simulation code ...
    await logger.info("simulation_completed", simulation_id=sim_id)
```

---

## 12. Log Sampling with Processor

**Better than manual sampling:** Built-in processor for sampling.

```python
# farm/utils/logging_config.py

class SamplingProcessor:
    """Processor to sample high-frequency logs."""
    
    def __init__(self, sample_rate: float = 1.0, events_to_sample: set = None):
        self.sample_rate = sample_rate
        self.events_to_sample = events_to_sample or set()
        self.counter = 0
    
    def __call__(self, logger, method_name, event_dict):
        event = event_dict.get("event", "")
        
        # Sample specific events
        if event in self.events_to_sample:
            self.counter += 1
            if self.counter % int(1.0 / self.sample_rate) != 0:
                raise structlog.DropEvent  # Drop this log
        
        return event_dict

# Add to processor chain
processors: list[Processor] = [
    # ...
    SamplingProcessor(
        sample_rate=0.1,  # 10% sampling
        events_to_sample={"agent_action", "resource_consumed"}
    ),
    # ...
]
```

---

## 13. Metrics Integration

**Use Case:** Log metrics alongside events for monitoring.

```python
# farm/utils/logging_metrics.py

import structlog
from typing import Dict, Any
import time

class MetricsProcessor:
    """Processor to track metrics from logs."""
    
    def __init__(self):
        self.metrics: Dict[str, list] = {}
        self.start_time = time.time()
    
    def __call__(self, logger, method_name, event_dict):
        # Track duration metrics
        if "duration_ms" in event_dict:
            event = event_dict.get("event", "unknown")
            if event not in self.metrics:
                self.metrics[event] = []
            self.metrics[event].append(event_dict["duration_ms"])
        
        # Add runtime to all logs
        event_dict["runtime_seconds"] = time.time() - self.start_time
        
        return event_dict
    
    def get_summary(self) -> Dict[str, Any]:
        """Get metrics summary."""
        import statistics
        
        summary = {}
        for event, durations in self.metrics.items():
            summary[event] = {
                "count": len(durations),
                "mean": statistics.mean(durations),
                "median": statistics.median(durations),
                "max": max(durations),
                "min": min(durations),
            }
        return summary

# Usage
metrics_processor = MetricsProcessor()

processors: list[Processor] = [
    # ...
    metrics_processor,
    # ...
]

# Get summary at end of simulation
summary = metrics_processor.get_summary()
logger.info("simulation_metrics", metrics=summary)
```

---

## 14. Better Console Rendering for Development

**Current:** Basic colored console.

**Better:** Rich console with more features.

```python
# farm/utils/logging_config.py

# For development, use rich console rendering
if environment == "development":
    try:
        from structlog.dev import ConsoleRenderer, RichTracebackFormatter
        
        processors.append(
            ConsoleRenderer(
                colors=enable_colors,
                # Rich exception formatting with syntax highlighting
                exception_formatter=RichTracebackFormatter(
                    show_locals=True,  # Show local variables in traceback
                    max_frames=10,  # Limit traceback depth
                    width=120,  # Console width
                ),
                # Sort keys for consistent output
                sort_keys=False,
                # Add columns
                columns=[
                    structlog.dev.Column(
                        "timestamp",
                        structlog.dev.KeyValueColumnFormatter(
                            key_style="dim",
                            value_style="dim",
                            reset_style="",
                            value_repr=str,
                        ),
                    ),
                    structlog.dev.Column(
                        "",
                        structlog.dev.get_default_log_renderer(colors=enable_colors),
                    ),
                ],
            )
        )
    except ImportError:
        # Fallback to basic console renderer
        processors.append(structlog.dev.ConsoleRenderer(colors=enable_colors))
```

---

## 15. Log Rotation with Handler

**Use Case:** Prevent log files from growing indefinitely.

```python
# farm/utils/logging_config.py

from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler

def configure_logging(...):
    # ... existing code ...
    
    if log_dir:
        log_path = Path(log_dir)
        log_path.mkdir(parents=True, exist_ok=True)
        
        # Rotating file handler (size-based)
        rotating_handler = RotatingFileHandler(
            log_path / "application.log",
            maxBytes=10 * 1024 * 1024,  # 10 MB
            backupCount=5,  # Keep 5 backup files
        )
        rotating_handler.setLevel(numeric_level)
        rotating_handler.setFormatter(text_formatter)
        logging.root.addHandler(rotating_handler)
        
        # Time-based rotation (daily)
        timed_handler = TimedRotatingFileHandler(
            log_path / "application.daily.log",
            when="midnight",  # Rotate at midnight
            interval=1,  # Every 1 day
            backupCount=30,  # Keep 30 days
        )
        timed_handler.setLevel(numeric_level)
        timed_handler.setFormatter(text_formatter)
        logging.root.addHandler(timed_handler)
```

---

## 16. Simulation-Specific Logger with Typing

**Use Case:** Type-safe logging for simulation events.

```python
# farm/utils/simulation_logger.py

from typing import Protocol, runtime_checkable
import structlog

@runtime_checkable
class SimulationLogger(Protocol):
    """Type-safe protocol for simulation logging."""
    
    def log_agent_action(
        self,
        agent_id: str,
        action: str,
        success: bool,
        **kwargs
    ) -> None: ...
    
    def log_population_change(
        self,
        population: int,
        change: int,
        step: int,
    ) -> None: ...
    
    def log_resource_update(
        self,
        total_resources: float,
        active_nodes: int,
        step: int,
    ) -> None: ...

class TypedSimulationLogger:
    """Typed logger wrapper for simulation events."""
    
    def __init__(self, logger: structlog.stdlib.BoundLogger):
        self.logger = logger
    
    def log_agent_action(
        self,
        agent_id: str,
        action: str,
        success: bool,
        **kwargs
    ) -> None:
        """Log agent action with type safety."""
        self.logger.info(
            "agent_action",
            agent_id=agent_id,
            action=action,
            success=success,
            **kwargs
        )
    
    def log_population_change(
        self,
        population: int,
        change: int,
        step: int,
    ) -> None:
        """Log population change."""
        self.logger.info(
            "population_changed",
            population=population,
            change=change,
            step=step,
        )
    
    def log_resource_update(
        self,
        total_resources: float,
        active_nodes: int,
        step: int,
    ) -> None:
        """Log resource update."""
        self.logger.debug(
            "resources_updated",
            total=total_resources,
            active=active_nodes,
            step=step,
        )

# Usage with type checking
def run_simulation(logger: SimulationLogger):
    logger.log_agent_action(
        agent_id="agent_001",
        action="move",
        success=True,
    )  # Type checker validates parameters
```

---

## Recommended Implementation Priority

### Immediate (High Impact, Low Effort):
1. âœ… **TimeStamper** - Replace custom timestamp (5 min)
2. âœ… **filter_by_level** - Performance optimization (5 min)
3. âœ… **Log rotation** - Prevent disk issues (10 min)
4. âœ… **Testing support** - Better unit tests (15 min)

### Soon (Medium Impact):
5. âœ… **dict_tracebacks** - Better exception data (10 min)
6. âœ… **UnicodeDecoder/Encoder** - Handle encoding (5 min)
7. âœ… **Correlation IDs** - Track related events (20 min)
8. âœ… **Metrics processor** - Built-in metrics (30 min)

### Later (Nice to Have):
9. âœ… **Thread-local context** - Only if using parallel experiments
10. âœ… **Async logging** - Only if performance critical
11. âœ… **Typed loggers** - Better IDE support
12. âœ… **Custom context class** - Micro-optimization

---

## Complete Example Configuration

```python
# farm/utils/logging_config_advanced.py

def configure_logging_advanced(
    environment: str = "development",
    log_dir: Optional[str] = None,
    log_level: str = "INFO",
    enable_metrics: bool = False,
    use_threadlocal: bool = False,
    enable_correlation: bool = True,
) -> None:
    """Advanced logging configuration with all recommended features."""
    
    # Metrics processor (optional)
    metrics_processor = MetricsProcessor() if enable_metrics else None
    
    # Build processor chain with optimizations
    processors: list[Processor] = [
        # Context management (thread-local or contextvars)
        structlog.threadlocal.merge_threadlocal if use_threadlocal
        else structlog.contextvars.merge_contextvars,
        
        # Early processors (cheap)
        add_log_level,
        add_log_level_number,
        
        # Filter disabled levels ASAP (performance)
        structlog.stdlib.filter_by_level,
        
        # Unicode safety
        structlog.processors.UnicodeDecoder(),
        
        # Add metadata
        add_logger_name,
        structlog.processors.TimeStamper(fmt="iso", utc=True, key="timestamp"),
        
        # Stack and exception info
        structlog.processors.StackInfoRenderer(),
        structlog.processors.dict_tracebacks,
        
        # Security
        censor_sensitive_data,
        
        # Custom processors
        *(
            [metrics_processor] if metrics_processor else []
        ),
        PerformanceLogger(slow_threshold_ms=100.0),
        
        # Callsite info (expensive - only in dev)
        *(
            [structlog.processors.CallsiteParameterAdder({
                structlog.processors.CallsiteParameter.FILENAME,
                structlog.processors.CallsiteParameter.FUNC_NAME,
                structlog.processors.CallsiteParameter.LINENO,
            })]
            if environment == "development"
            else []
        ),
        
        # Event renaming (optional)
        structlog.processors.EventRenamer(to="message"),
        
        # Unicode output
        structlog.processors.UnicodeEncoder(encoding="utf-8"),
        
        # Final renderer
        structlog.processors.JSONRenderer() if environment == "production"
        else structlog.dev.ConsoleRenderer(colors=True),
    ]
    
    # Configure structlog
    structlog.configure(
        processors=processors,
        wrapper_class=structlog.make_filtering_bound_logger(numeric_level),
        context_class=(
            structlog.threadlocal.wrap_dict(dict) if use_threadlocal
            else dict
        ),
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )
    
    # Setup rotating file handlers
    if log_dir:
        setup_rotating_handlers(log_dir, numeric_level)
    
    logger = get_logger(__name__)
    logger.info(
        "logging_configured",
        environment=environment,
        features={
            "metrics": enable_metrics,
            "threadlocal": use_threadlocal,
            "correlation": enable_correlation,
        }
    )
```

---

## Summary

### Must Add:
1. **filter_by_level** - 20-50% performance improvement
2. **TimeStamper** - More efficient timestamps
3. **Log rotation** - Prevent disk issues

### Should Add:
4. **dict_tracebacks** - Better exception data
5. **Testing support** - Unit test your logging
6. **Correlation IDs** - Track related events

### Nice to Have:
7. **Thread-local context** - If using parallel experiments
8. **Metrics processor** - Built-in metrics tracking
9. **Typed loggers** - Better IDE support

All of these features are production-ready, well-documented, and actively maintained by the structlog team!
